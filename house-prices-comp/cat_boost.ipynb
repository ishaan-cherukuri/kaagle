{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e64d145",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "This notebook is a simple attempt to show how far you can go with CatBoost using only the basics: imputing missing values and applying an ordinal encoder for categorical features.\n",
    "\n",
    "CatBoost handles much of the heavy lifting internally, so there’s no extensive preprocessing, feature scaling, or complex ensembling involved here. **At the time of writing, this setup achieves a score of about 0.1196 on the public Leader Board (233).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb1a19",
   "metadata": {},
   "source": [
    "# **Important Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655070d",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f79cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\", keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132254fd",
   "metadata": {},
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=100,figsize=(15,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9430c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features — confirmed from dataset column names\n",
    "numerical_cols = [\n",
    "    'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "    'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "    'GrLivArea', 'GarageArea', 'GarageCars', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
    "    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'MoSold',\n",
    "    'YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'OverallQual', 'OverallCond'\n",
    "]\n",
    "\n",
    "# Ordinal columns with their order preserved\n",
    "ordinal_map = {\n",
    "    'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtExposure': ['NA', 'No', 'Mn', 'Av', 'Gd'],\n",
    "    'BsmtFinType1': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'BsmtFinType2': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Functional': ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "    'FireplaceQu': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageFinish': ['NA', 'Unf', 'RFn', 'Fin'],\n",
    "    'GarageQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PavedDrive': ['N', 'P', 'Y'],\n",
    "    'PoolQC': ['NA', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Fence': ['NA', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']\n",
    "}\n",
    "ordinal_cols = list(ordinal_map.keys())\n",
    "\n",
    "# Nominal (non-ordinal) categorical features — matched to real names\n",
    "nominal_cols = [\n",
    "    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "    'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "    'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating',\n",
    "    'CentralAir', 'Electrical', 'GarageType', 'MiscFeature',\n",
    "    'SaleType', 'SaleCondition'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a89a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"SalePrice\"] # Identify Target Variable\n",
    "df = df.drop(columns=[\"SalePrice\", \"Id\"])  # Drop ID \n",
    "\n",
    "missing_like = ['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', '', ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88787a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and Impute Numerical Cols\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].replace(missing_like, np.nan)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605acc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode ordinal columns \n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1,\n",
    "    categories=[[str(cat) for cat in ordinal_map[col]] for col in ordinal_cols]\n",
    ")\n",
    "df[ordinal_cols] = ordinal_encoder.fit_transform(df[ordinal_cols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpute Nominal columns and fill missing\n",
    "for col in nominal_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace(missing_like, 'missing')\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8666308",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = nominal_cols  # Nominal features only for CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b014b",
   "metadata": {},
   "source": [
    "Note: Any EDA steps and imputations applied to the training data must also be consistently applied to the test data; this ensures the model receives data in the same format during prediction, preventing errors or mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/test.csv\", keep_default_na=False)\n",
    "final_df = df_test[[\"Id\"]] # This Frame will be our final result after modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64592580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "for col in numerical_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(missing_like, np.nan)\n",
    "        df_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
    "        median_val = df[col].median()  # use median from training data\n",
    "        df_test[col] = df_test[col].fillna(median_val)\n",
    "\n",
    "df_test = df_test[df.columns]  # X is your original train set (post-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal columns\n",
    "for col in ordinal_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(missing_like, 'missing')\n",
    "        df_test[col] = df_test[col].fillna('missing')\n",
    "\n",
    "df_test[ordinal_cols] = ordinal_encoder.transform(df_test[ordinal_cols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal categorical columns\n",
    "for col in nominal_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(missing_like, 'missing')\n",
    "        df_test[col] = df_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb219225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df.columns]  # df is your original train set (post-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d0ea34",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(silent=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d930ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters for our random search cross validation\n",
    "param_dist = {\n",
    "    'depth': [4, 10],\n",
    "    'learning_rate': [0.01, 0.2],\n",
    "    'iterations': [300, 1500],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'border_count': [32, 64, 128]\n",
    "}\n",
    "\n",
    "cat_cols = [col for col in nominal_cols if col in df.columns] # We only use nominal cols as category due to orindal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Adjust as needed\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1 ,\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d45eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model (CatBoost will internally handle categorical columns)\n",
    "random_search.fit(df, y, cat_features=cat_cols)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best RMSE score:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = random_search.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"SalePrice\"] = preds\n",
    "final_df # Looking at predictions before exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"predicted_sales_prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea4691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
