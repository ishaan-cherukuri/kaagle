{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4830626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9430c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features — confirmed from dataset column names\n",
    "numerical_cols = [\n",
    "    'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "    'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "    'GrLivArea', 'GarageArea', 'GarageCars', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
    "    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'MoSold',\n",
    "    'YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'OverallQual', 'OverallCond'\n",
    "]\n",
    "\n",
    "# Ordinal columns with their order preserved\n",
    "ordinal_map = {\n",
    "    'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtExposure': ['NA', 'No', 'Mn', 'Av', 'Gd'],\n",
    "    'BsmtFinType1': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'BsmtFinType2': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Functional': ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "    'FireplaceQu': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageFinish': ['NA', 'Unf', 'RFn', 'Fin'],\n",
    "    'GarageQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PavedDrive': ['N', 'P', 'Y'],\n",
    "    'PoolQC': ['NA', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Fence': ['NA', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']\n",
    "}\n",
    "ordinal_cols = list(ordinal_map.keys())\n",
    "\n",
    "# Nominal (non-ordinal) categorical features — matched to real names\n",
    "nominal_cols = [\n",
    "    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "    'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "    'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating',\n",
    "    'CentralAir', 'Electrical', 'GarageType', 'MiscFeature',\n",
    "    'SaleType', 'SaleCondition'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e6e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# === Step 1: Load Data ===\n",
    "df = pd.read_csv(\"data/train.csv\", keep_default_na=False)\n",
    "\n",
    "# === Step 2: Identify target ===\n",
    "y = np.log1p(df[\"SalePrice\"])\n",
    "df = df.drop(columns=[\"SalePrice\", \"Id\"])  # Drop ID if present\n",
    "\n",
    "# === Step 3: Setup categorical column lists ===\n",
    "# nominal_cols and ordinal_map should be defined before this code block\n",
    "cat_cols = nominal_cols  # Nominal features only for CatBoost\n",
    "\n",
    "# === Step 4: Data Cleaning & Transformation ===\n",
    "\n",
    "# --- Clean and impute numerical columns ---\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].replace(['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', ''], np.nan)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# --- Encode ordinal columns ---\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1,\n",
    "    categories=[[str(cat) for cat in ordinal_map[col]] for col in ordinal_cols]\n",
    ")\n",
    "\n",
    "missing_like = ['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', '', ' ']\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace(missing_like, 'missing')\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        \n",
    "df[ordinal_cols] = ordinal_encoder.fit_transform(df[ordinal_cols].astype(str))\n",
    "\n",
    "# --- Convert nominal features to string and fill missing as well as dealing with rare values ---\n",
    "rare_label_dict = {}\n",
    "for col in nominal_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace(missing_like, 'missing')\n",
    "        freqs = df[col].value_counts(normalize=True)\n",
    "        rare_labels = freqs[freqs < 0.01].index\n",
    "        df[col] = df[col].replace(rare_labels, 'Rare')\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "        rare_label_dict[col] = set(rare_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64592580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume:\n",
    "# - `df` was your training data with 'SalePrice'\n",
    "# - `df_test` is your test data WITHOUT 'SalePrice'\n",
    "# - `numerical_cols`, `ordinal_cols`, `nominal_cols`, and `cat_features`\n",
    "#   were defined and used during training\n",
    "# - `ordinal_encoder`, `catboost_model` were already fitted using training data\n",
    "# - `X.columns` gives you the correct column order for prediction\n",
    "\n",
    "df_test = pd.read_csv(\"data/test.csv\", keep_default_na=False)\n",
    "\n",
    "final_df = df_test[[\"Id\"]] \n",
    "\n",
    "# Step 1: Replace missing-like strings\n",
    "missing_like = ['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', '', ' ']\n",
    "\n",
    "# Numerical columns\n",
    "for col in numerical_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(missing_like, np.nan)\n",
    "        df_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
    "        median_val = df[col].median()  # use median from training data\n",
    "        df_test[col] = df_test[col].fillna(median_val)\n",
    "\n",
    "df[ordinal_cols] = ordinal_encoder.fit_transform(df[ordinal_cols].astype(str))\n",
    "\n",
    "# Ordinal columns\n",
    "for col in ordinal_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(missing_like, 'missing')\n",
    "        df_test[col] = df_test[col].fillna('missing')\n",
    "\n",
    "df_test[ordinal_cols] = ordinal_encoder.transform(df_test[ordinal_cols].astype(str))\n",
    "\n",
    "# Nominal categorical columns (used by CatBoost)\n",
    "for col in nominal_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(missing_like, 'missing')\n",
    "        df_test[col] = df_test[col].apply(lambda x: 'Rare' if x in rare_label_dict[col] else x)\n",
    "        df_test[col] = df_test[col].astype('category')\n",
    "\n",
    "# Step 2: Reorder columns to match training data\n",
    "df_test = df_test[df.columns]  # X is your original train set (post-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48044ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     22\u001b[39m bayes_search = BayesSearchCV(\n\u001b[32m     23\u001b[39m     estimator=model,\n\u001b[32m     24\u001b[39m     search_spaces=search_spaces,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Fit the model (CatBoost will internally handle categorical columns)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mbayes_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# === Step 7: Best Model ===\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters:\u001b[39m\u001b[33m\"\u001b[39m, bayes_search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/skopt/searchcv.py:542\u001b[39m, in \u001b[36mBayesSearchCV.fit\u001b[39m\u001b[34m(self, X, y, groups, callback, **fit_params)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.refit):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBayesSearchCV doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt support a callable refit, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt define an implicit score to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moptimize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_train_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/skopt/searchcv.py:599\u001b[39m, in \u001b[36mBayesSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter > \u001b[32m0\u001b[39m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[32m    597\u001b[39m     n_points_adjusted = \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     optim_result, score_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m     n_iter -= n_points\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/skopt/searchcv.py:453\u001b[39m, in \u001b[36mBayesSearchCV._step\u001b[39m\u001b[34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[32m    451\u001b[39m params_dict = [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m all_results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# === Step 5: Define CatBoost Model and Search Space ===\n",
    "model = CatBoostRegressor(silent=True, random_state=42)\n",
    "\n",
    "search_spaces = {\n",
    "    'depth': Integer(4, 10),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "    'iterations': Integer(300, 1500),\n",
    "    'l2_leaf_reg': Integer(1, 9),\n",
    "    'border_count': Integer(32, 128),\n",
    "    'bagging_temperature': Real(0.0, 1.0),\n",
    "    'random_strength': Integer(1, 10),\n",
    "}\n",
    "\n",
    "# Make sure cat_features uses column names\n",
    "cat_features = [col for col in cat_cols if col in df.columns]\n",
    "\n",
    "# === Step 6: Run Bayesian Search ===\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=search_spaces,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_iter=20,  # Increase to 50+ for better optimization\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model (CatBoost will internally handle categorical columns)\n",
    "bayes_search.fit(df, y, cat_features=cat_features)\n",
    "\n",
    "# === Step 7: Best Model ===\n",
    "print(\"Best parameters:\", bayes_search.best_params_)\n",
    "print(\"Best RMSE score:\", -bayes_search.best_score_)\n",
    "\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "preds = best_model.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"SalePrice\"] = predictions\n",
    "final_df.to_csv(\"submissions/final_submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977bb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
