{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4830626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9430c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features — confirmed from dataset column names\n",
    "numerical_cols = [\n",
    "    \"LotFrontage\", 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "    'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "    'GrLivArea', 'GarageArea', 'GarageCars', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
    "    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'MoSold',\n",
    "    'YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'OverallQual', 'OverallCond'\n",
    "]\n",
    "\n",
    "# Ordinal columns with their order preserved\n",
    "ordinal_map = {\n",
    "    'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtExposure': ['NA', 'No', 'Mn', 'Av', 'Gd'],\n",
    "    'BsmtFinType1': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'BsmtFinType2': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Functional': ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "    'FireplaceQu': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageFinish': ['NA', 'Unf', 'RFn', 'Fin'],\n",
    "    'GarageQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PavedDrive': ['N', 'P', 'Y'],\n",
    "    'PoolQC': ['NA', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Fence': ['NA', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']\n",
    "}\n",
    "ordinal_cols = list(ordinal_map.keys())\n",
    "\n",
    "# Nominal (non-ordinal) categorical features — matched to real names\n",
    "nominal_cols = [\n",
    "    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "    'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "    'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating',\n",
    "    'CentralAir', 'Electrical', 'GarageType', 'MiscFeature',\n",
    "    'SaleType', 'SaleCondition'\n",
    "]\n",
    "\n",
    "nominal_cols_clean = [\n",
    "    'MSSubClass', 'MSZoning', 'Street', 'LandContour', 'LotConfig',\n",
    "    'LandSlope', 'Neighborhood', 'BldgType', 'HouseStyle', 'RoofStyle',\n",
    "    'RoofMatl', 'Exterior1st', 'Exterior2nd', 'Foundation', 'Heating',\n",
    "    'Electrical', 'SaleType'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ee3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", keep_default_na=False)\n",
    "test = pd.read_csv(\"data/test.csv\", keep_default_na=False)\n",
    "\n",
    "concat_df = pd.concat([train, test])\n",
    "\n",
    "train_test = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc9877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in train_test:\n",
    "    # Alley : data description says NA means \"no alley access\"\n",
    "    df.loc[:, \"Alley\"] = df.loc[:, \"Alley\"].fillna(\"None\")\n",
    "    # BedroomAbvGr : NA most likely means 0\n",
    "    df.loc[:, \"BedroomAbvGr\"] = df.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "    # BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "    df.loc[:, \"BsmtQual\"] = df.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "    df.loc[:, \"BsmtCond\"] = df.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "    df.loc[:, \"BsmtExposure\"] = df.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "    df.loc[:, \"BsmtFinType1\"] = df.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "    df.loc[:, \"BsmtFinType2\"] = df.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "    df.loc[:, \"BsmtFullBath\"] = df.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "    df.loc[:, \"BsmtHalfBath\"] = df.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "    df.loc[:, \"BsmtUnfSF\"] = df.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "    # CentralAir : NA most likely means No\n",
    "    df.loc[:, \"CentralAir\"] = df.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "    # Condition : NA most likely means Normal\n",
    "    df.loc[:, \"Condition1\"] = df.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "    df.loc[:, \"Condition2\"] = df.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "    # EnclosedPorch : NA most likely means no enclosed porch\n",
    "    df.loc[:, \"EnclosedPorch\"] = df.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "    # External stuff : NA most likely means average\n",
    "    df.loc[:, \"ExterCond\"] = df.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "    df.loc[:, \"ExterQual\"] = df.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "    # Fence : data description says NA means \"no fence\"\n",
    "    df.loc[:, \"Fence\"] = df.loc[:, \"Fence\"].fillna(\"No\")\n",
    "    # FireplaceQu : data description says NA means \"no fireplace\"\n",
    "    df.loc[:, \"FireplaceQu\"] = df.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "    df.loc[:, \"Fireplaces\"] = df.loc[:, \"Fireplaces\"].fillna(0)\n",
    "    # Functional : data description says NA means typical\n",
    "    df.loc[:, \"Functional\"] = df.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "    # GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "    df.loc[:, \"GarageType\"] = df.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "    df.loc[:, \"GarageFinish\"] = df.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "    df.loc[:, \"GarageQual\"] = df.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "    df.loc[:, \"GarageCond\"] = df.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "    df.loc[:, \"GarageArea\"] = df.loc[:, \"GarageArea\"].fillna(0)\n",
    "    df.loc[:, \"GarageCars\"] = df.loc[:, \"GarageCars\"].fillna(0)\n",
    "    # HalfBath : NA most likely means no half baths above grade\n",
    "    df.loc[:, \"HalfBath\"] = df.loc[:, \"HalfBath\"].fillna(0)\n",
    "    # HeatingQC : NA most likely means typical\n",
    "    df.loc[:, \"HeatingQC\"] = df.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "    # KitchenAbvGr : NA most likely means 0\n",
    "    df.loc[:, \"KitchenAbvGr\"] = df.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "    # KitchenQual : NA most likely means typical\n",
    "    df.loc[:, \"KitchenQual\"] = df.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "    # LotFrontage : NA most likely means no lot frontage\n",
    "    df.loc[:, \"LotFrontage\"] = df.loc[:, \"LotFrontage\"].fillna(0)\n",
    "    # LotShape : NA most likely means regular\n",
    "    df.loc[:, \"LotShape\"] = df.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "    # MasVnrType : NA most likely means no veneer\n",
    "    df.loc[:, \"MasVnrType\"] = df.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "    df.loc[:, \"MasVnrArea\"] = df.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "    # MiscFeature : data description says NA means \"no misc feature\"\n",
    "    df.loc[:, \"MiscFeature\"] = df.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "    df.loc[:, \"MiscVal\"] = df.loc[:, \"MiscVal\"].fillna(0)\n",
    "    # OpenPorchSF : NA most likely means no open porch\n",
    "    df.loc[:, \"OpenPorchSF\"] = df.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "    # PavedDrive : NA most likely means not paved\n",
    "    df.loc[:, \"PavedDrive\"] = df.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "    # PoolQC : data description says NA means \"no pool\"\n",
    "    df.loc[:, \"PoolQC\"] = df.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "    df.loc[:, \"PoolArea\"] = df.loc[:, \"PoolArea\"].fillna(0)\n",
    "    # SaleCondition : NA most likely means normal sale\n",
    "    df.loc[:, \"SaleCondition\"] = df.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "    # ScreenPorch : NA most likely means no screen porch\n",
    "    df.loc[:, \"ScreenPorch\"] = df.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "    # TotRmsAbvGrd : NA most likely means 0\n",
    "    df.loc[:, \"TotRmsAbvGrd\"] = df.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "    # Utilities : NA most likely means all public utilities\n",
    "    df.loc[:, \"Utilities\"] = df.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "    # WoodDeckSF : NA most likely means no wood deck\n",
    "    df.loc[:, \"WoodDeckSF\"] = df.loc[:, \"WoodDeckSF\"].fillna(0)\n",
    "    df = df.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e6e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# === Step 2: Identify target ===\n",
    "y = train[\"SalePrice\"]\n",
    "train = train.drop(columns=[\"SalePrice\", \"Id\"])  \n",
    "\n",
    "cat_cols = nominal_cols \n",
    "\n",
    "# === Step 4: Data Cleaning & Transformation ===\n",
    "\n",
    "# --- Clean and impute numerical columns ---\n",
    "for col in numerical_cols:\n",
    "    train[col] = train[col].replace(['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', ''], np.nan)\n",
    "    train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "    concat_df[col] = pd.to_numeric(concat_df[col], errors='coerce')\n",
    "    train[col] = train[col].fillna(concat_df[col].median())\n",
    "\n",
    "\n",
    "# --- Encode ordinal columns ---\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1,\n",
    "    categories=[[str(cat) for cat in ordinal_map[col]] for col in ordinal_cols]\n",
    ")\n",
    "\n",
    "missing_like = ['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', '', ' ']\n",
    "\n",
    "train[ordinal_cols] = ordinal_encoder.fit_transform(train[ordinal_cols].astype(str))\n",
    "\n",
    "# --- Convert nominal features to string and fill missing ---\n",
    "for col in nominal_cols_clean:\n",
    "    if col in train.columns:\n",
    "        train[col] = train[col].replace(missing_like, 'missing')\n",
    "        train[col] = train[col].fillna('missing')\n",
    "\n",
    "train[nominal_cols] = train[nominal_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64592580",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = test[[\"Id\"]] \n",
    "\n",
    "# Step 1: Replace missing-like strings\n",
    "missing_like = ['NA', 'N/A', 'na', 'n/a', 'NaN', 'nan', 'None', 'none', '', ' ']\n",
    "\n",
    "# Numerical columns\n",
    "for col in numerical_cols:\n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].replace(missing_like, np.nan)\n",
    "        test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "        test[col] = test[col].fillna(concat_df[col].median())\n",
    "\n",
    "test[ordinal_cols] = ordinal_encoder.transform(test[ordinal_cols].astype(str))\n",
    "\n",
    "for col in nominal_cols_clean:\n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].replace(missing_like, 'missing')\n",
    "        \n",
    "test[nominal_cols] = test[nominal_cols].astype('category')\n",
    "\n",
    "test = test[train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d65ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     16\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m     17\u001b[39m     estimator=model,\n\u001b[32m     18\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Fit the model (CatBoost will internally handle categorical columns)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# === Step 7: Best Model ===\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters:\u001b[39m\u001b[33m\"\u001b[39m, random_search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# === Step 5: Define CatBoost Model and Search Space ===\n",
    "model = CatBoostRegressor(silent=True, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'iterations': [300, 500, 1000, 1500],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'border_count': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Make sure cat_features uses column names\n",
    "cat_features = [col for col in cat_cols if col in df.columns]\n",
    "\n",
    "# === Step 6: Run Randomized Search ===\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Adjust as needed\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model (CatBoost will internally handle categorical columns)\n",
    "random_search.fit(train, y, cat_features=cat_features)\n",
    "\n",
    "# === Step 7: Best Model ===\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best RMSE score:\", -random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "preds = best_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"SalePrice\"] = predictions\n",
    "final_df.to_csv(\"final_submission6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977bb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
